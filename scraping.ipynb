{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import difflib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/2. Scraping the hot topics to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.reddit.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= requests.get(base_url)\n",
    "html = response.content\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict={}\n",
    "\n",
    "#get all parent topics\n",
    "topic_parents = soup.select('#TOPICS faceplate-expandable-section-helper > details')\n",
    "\n",
    "#for all parent topics, find the parent topic name and list of subtopics\n",
    "for topic_parent in topic_parents:\n",
    "    #parent topic name\n",
    "    topic = topic_parent.find('summary')['aria-controls']\n",
    "\n",
    "    subtopics = topic_parent.select(f'ul left-nav-topic-tracker') \n",
    "\n",
    "    topic_dict[topic]= [subtopic['topic'] for subtopic in subtopics] #get the 'topic' attribute from each selected subtopics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Options \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internet Culture (Viral)</th>\n",
       "      <th>Games</th>\n",
       "      <th>Q&amp;As</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Pop Culture</th>\n",
       "      <th>Movies &amp; TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazing</td>\n",
       "      <td>action_games</td>\n",
       "      <td>q_and_as</td>\n",
       "      <td>3d_printing</td>\n",
       "      <td>celebrities</td>\n",
       "      <td>action_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animals_and_pets</td>\n",
       "      <td>adventure_games</td>\n",
       "      <td>stories_and_confessions</td>\n",
       "      <td>artificial_intelligence_and_machine_learning</td>\n",
       "      <td>creators_and_influencers</td>\n",
       "      <td>animated_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cringe_and_facepalm</td>\n",
       "      <td>esports</td>\n",
       "      <td>-</td>\n",
       "      <td>computers_and_hardware</td>\n",
       "      <td>generations_and_nostalgia</td>\n",
       "      <td>comedy_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>funny</td>\n",
       "      <td>gaming_consoles_and_gear</td>\n",
       "      <td>-</td>\n",
       "      <td>consumer_electronics</td>\n",
       "      <td>podcasts</td>\n",
       "      <td>crime_mystery_and_thriller_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interesting</td>\n",
       "      <td>gaming_news_and_discussion</td>\n",
       "      <td>-</td>\n",
       "      <td>diy_electronics</td>\n",
       "      <td>streamers</td>\n",
       "      <td>documentary_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>memes</td>\n",
       "      <td>mobile_games</td>\n",
       "      <td>-</td>\n",
       "      <td>programming</td>\n",
       "      <td>tarot_and_astrology</td>\n",
       "      <td>drama_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oddly_satisfying</td>\n",
       "      <td>other_games</td>\n",
       "      <td>-</td>\n",
       "      <td>software_and_apps</td>\n",
       "      <td>-</td>\n",
       "      <td>fantasy_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reddit_meta</td>\n",
       "      <td>role_playing_games</td>\n",
       "      <td>-</td>\n",
       "      <td>streaming_services</td>\n",
       "      <td>-</td>\n",
       "      <td>horror_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wholesome_and_heartwarming</td>\n",
       "      <td>simulation_games</td>\n",
       "      <td>-</td>\n",
       "      <td>tech_news_and_discussion</td>\n",
       "      <td>-</td>\n",
       "      <td>movie_news_and_discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>sports_and_racing_games</td>\n",
       "      <td>-</td>\n",
       "      <td>virtual_and_augmented_reality</td>\n",
       "      <td>-</td>\n",
       "      <td>reality_tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>strategy_games</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>romance_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>tabletop_games</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>scifi_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>superhero_movies_and_series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>tv_news_and_discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Internet Culture (Viral)                       Games  \\\n",
       "0                      amazing                action_games   \n",
       "1             animals_and_pets             adventure_games   \n",
       "2          cringe_and_facepalm                     esports   \n",
       "3                        funny    gaming_consoles_and_gear   \n",
       "4                  interesting  gaming_news_and_discussion   \n",
       "5                        memes                mobile_games   \n",
       "6             oddly_satisfying                 other_games   \n",
       "7                  reddit_meta          role_playing_games   \n",
       "8   wholesome_and_heartwarming            simulation_games   \n",
       "9                            -     sports_and_racing_games   \n",
       "10                           -              strategy_games   \n",
       "11                           -              tabletop_games   \n",
       "12                           -                           -   \n",
       "13                           -                           -   \n",
       "\n",
       "                       Q&As                                    Technology  \\\n",
       "0                  q_and_as                                   3d_printing   \n",
       "1   stories_and_confessions  artificial_intelligence_and_machine_learning   \n",
       "2                         -                        computers_and_hardware   \n",
       "3                         -                          consumer_electronics   \n",
       "4                         -                               diy_electronics   \n",
       "5                         -                                   programming   \n",
       "6                         -                             software_and_apps   \n",
       "7                         -                            streaming_services   \n",
       "8                         -                      tech_news_and_discussion   \n",
       "9                         -                 virtual_and_augmented_reality   \n",
       "10                        -                                             -   \n",
       "11                        -                                             -   \n",
       "12                        -                                             -   \n",
       "13                        -                                             -   \n",
       "\n",
       "                  Pop Culture                                   Movies & TV  \n",
       "0                 celebrities                      action_movies_and_series  \n",
       "1    creators_and_influencers                    animated_movies_and_series  \n",
       "2   generations_and_nostalgia                      comedy_movies_and_series  \n",
       "3                    podcasts  crime_mystery_and_thriller_movies_and_series  \n",
       "4                   streamers                 documentary_movies_and_series  \n",
       "5         tarot_and_astrology                       drama_movies_and_series  \n",
       "6                           -                     fantasy_movies_and_series  \n",
       "7                           -                      horror_movies_and_series  \n",
       "8                           -                     movie_news_and_discussion  \n",
       "9                           -                                    reality_tv  \n",
       "10                          -                     romance_movies_and_series  \n",
       "11                          -                       scifi_movies_and_series  \n",
       "12                          -                   superhero_movies_and_series  \n",
       "13                          -                        tv_news_and_discussion  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df= pd.DataFrame.from_dict(topic_dict, orient='index')\n",
    "topics_df= topics_df.T.fillna('-')\n",
    "print(\"Available Options \\n\")\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3d_printing', 'horror_movies_and_series', 'drama_movies_and_series', 'memes', 'programming', 'reddit_meta', 'tech_news_and_discussion', 'computers_and_hardware', 'q_and_as', 'documentary_movies_and_series', 'reality_tv', 'amazing', 'generations_and_nostalgia', 'streaming_services', 'action_movies_and_series', 'interesting', 'gaming_news_and_discussion', 'animals_and_pets', 'podcasts', 'tv_news_and_discussion', 'wholesome_and_heartwarming', 'role_playing_games', 'action_games', 'superhero_movies_and_series', 'tarot_and_astrology', 'cringe_and_facepalm', 'adventure_games', 'gaming_consoles_and_gear', 'funny', 'oddly_satisfying', 'scifi_movies_and_series', 'mobile_games', 'stories_and_confessions', 'esports', 'diy_electronics', 'consumer_electronics', 'software_and_apps', 'strategy_games', 'movie_news_and_discussion', 'comedy_movies_and_series', 'sports_and_racing_games', 'celebrities', 'fantasy_movies_and_series', 'streamers', 'creators_and_influencers', 'other_games', 'tabletop_games', 'virtual_and_augmented_reality', 'crime_mystery_and_thriller_movies_and_series', 'artificial_intelligence_and_machine_learning', 'simulation_games', 'romance_movies_and_series', 'animated_movies_and_series'}\n"
     ]
    }
   ],
   "source": [
    "possible_values = set(topics_df.values.flatten().tolist())\n",
    "possible_values.discard(\"-\")\n",
    "print(possible_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_topic(input_topic):\n",
    "    closest_match = difflib.get_close_matches(input_topic, possible_values, n=3, cutoff=0.5)\n",
    "\n",
    "    return closest_match if closest_match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_topic = input('Enter the topic to scrape for')\n",
    "\n",
    "while input_topic not in possible_values:\n",
    "    closest_topics = find_closest_topic(input_topic)\n",
    "\n",
    "    if closest_topics is not None:\n",
    "        input_topic = input(f'Enter valid topic name. Did you mean? {closest_topics}')\n",
    "    else:\n",
    "        input_topic = input('Enter valid topic name.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazing'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/2. Scraping the content in chosen topic:\n",
    "TODO:\n",
    "- [x] Obtain videos and images with their OP info\n",
    "- [x] Store in dataFrame and export to csv\n",
    "- [ ] Fix bad src links\n",
    "- [ ] Fix untimely breaking of scroll\n",
    "- [ ] Download media and include a path in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_target_url = base_url + \"t/\" + input_topic\n",
    "target_count = 90\n",
    "items = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(scrape_target_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14514"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "previous_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dict_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_content():\n",
    "    global target_count\n",
    "    elements = driver.find_elements(By.XPATH, '//*[@id=\"topic-tabs\"]/section[1]/shreddit-feed/article')\n",
    "\n",
    "    for i in range(len(elements)):\n",
    "        content_dict= {}\n",
    "        info_tag = elements[i].find_element(By.TAG_NAME, 'shreddit-post')\n",
    "\n",
    "        content_type = info_tag.get_attribute('post-type')\n",
    "\n",
    "        if content_type == 'image':\n",
    "                \n",
    "            img_tag = info_tag.find_elements(By.CSS_SELECTOR, 'div.relative > shreddit-aspect-ratio > shreddit-media-lightbox-listener > div > img')\n",
    "            img_src = img_tag[0].get_attribute('src')\n",
    "            src = img_src\n",
    "\n",
    "        elif content_type == 'video':\n",
    "            video_tag = info_tag.find_element(By.CSS_SELECTOR, 'div.relative > shreddit-aspect-ratio > shreddit-async-loader > media-telemetry-observer > shreddit-player')\n",
    "            video_src = video_tag.get_attribute('src')\n",
    "            src = video_src\n",
    "\n",
    "        else:\n",
    "            src = None\n",
    "            \n",
    "\n",
    "        content_dict = {\n",
    "            'title': info_tag.get_attribute('post-title'),\n",
    "            'subreddit_id': info_tag.get_attribute('subreddit-id'),\n",
    "            'subreddit': info_tag.get_attribute('subreddit-prefixed-name'),\n",
    "            'author': info_tag.get_attribute('author'),\n",
    "            'upvotes': info_tag.get_attribute('score'),\n",
    "            'comments': info_tag.get_attribute('comment-count'),\n",
    "            'type': info_tag.get_attribute('post-type'),\n",
    "            'source': src\n",
    "        }\n",
    "\n",
    "        if (content_dict not in content_dict_list) and (len(content_dict_list) < target_count):\n",
    "            content_dict_list.append(content_dict)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        print (len(content_dict_list))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while target_count > len(content_dict_list):\n",
    "    \n",
    "    # wait for some time or wait until loaded\n",
    "    time.sleep(5)\n",
    "\n",
    "    # get all the available content\n",
    "    get_available_content()\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight /8);\")\n",
    "\n",
    "    time.sleep(5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    if new_height == previous_height:\n",
    "        print('breaking')\n",
    "        break\n",
    "\n",
    "    previous_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "body = driver.find_element(By.TAG_NAME, 'body')\n",
    "\n",
    "while target_count > len(content_dict_list):\n",
    "    time.sleep(3)\n",
    "    get_available_content()\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dude makes aquaman look like a regular mermaid</td>\n",
       "      <td>t5_m0bnr</td>\n",
       "      <td>r/nextfuckinglevel</td>\n",
       "      <td>Agitated_Ad_1095</td>\n",
       "      <td>9888</td>\n",
       "      <td>225</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/fx2gtspphc6d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True definition of trust the process</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>Remote_Return1716</td>\n",
       "      <td>3336</td>\n",
       "      <td>71</td>\n",
       "      <td>video</td>\n",
       "      <td>https://v.redd.it/15huvf874d6d1/HLSPlaylist.m3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This girl's flips are definitely top talent</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>reflective_map21</td>\n",
       "      <td>7594</td>\n",
       "      <td>185</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/0ngywg4swb6d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This amazing converted campervan is bigger tha...</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>Majoodeh</td>\n",
       "      <td>2447</td>\n",
       "      <td>117</td>\n",
       "      <td>video</td>\n",
       "      <td>https://v.redd.it/cvvwhzbh8c6d1/HLSPlaylist.m3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chaser: The Smartest Dog in the World, Who Cou...</td>\n",
       "      <td>t5_m0bnr</td>\n",
       "      <td>r/nextfuckinglevel</td>\n",
       "      <td>Mad_Bulls_007</td>\n",
       "      <td>1363</td>\n",
       "      <td>49</td>\n",
       "      <td>video</td>\n",
       "      <td>https://v.redd.it/9q8pct7trc6d1/HLSPlaylist.m3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>The art of Cinematography</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>Ultimate_Kurix</td>\n",
       "      <td>1371</td>\n",
       "      <td>12</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/zhekp1j1x56d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Steam through a prism refracted sunbeam matchi...</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>Natashaalovelyy</td>\n",
       "      <td>156</td>\n",
       "      <td>11</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/oag19gg7d96d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Japanese Firefighters training</td>\n",
       "      <td>t5_m0bnr</td>\n",
       "      <td>r/nextfuckinglevel</td>\n",
       "      <td>Parasyte-vn</td>\n",
       "      <td>30240</td>\n",
       "      <td>491</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/oywy19clb26d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Absolute unit of a cow stands over 6ft tall</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>Sunnyudd</td>\n",
       "      <td>2229</td>\n",
       "      <td>89</td>\n",
       "      <td>video</td>\n",
       "      <td>https://packaged-media.redd.it/9j4y0ykkx46d1/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>The French Navy's bagpipe banger</td>\n",
       "      <td>t5_363r3</td>\n",
       "      <td>r/BeAmazed</td>\n",
       "      <td>freudian_nipps</td>\n",
       "      <td>705</td>\n",
       "      <td>59</td>\n",
       "      <td>video</td>\n",
       "      <td>https://v.redd.it/cxton7okm66d1/HLSPlaylist.m3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title subreddit_id  \\\n",
       "0      Dude makes aquaman look like a regular mermaid     t5_m0bnr   \n",
       "1                True definition of trust the process     t5_363r3   \n",
       "2         This girl's flips are definitely top talent     t5_363r3   \n",
       "3   This amazing converted campervan is bigger tha...     t5_363r3   \n",
       "4   Chaser: The Smartest Dog in the World, Who Cou...     t5_m0bnr   \n",
       "..                                                ...          ...   \n",
       "85                         The art of Cinematography      t5_363r3   \n",
       "86  Steam through a prism refracted sunbeam matchi...     t5_363r3   \n",
       "87                    Japanese Firefighters training      t5_m0bnr   \n",
       "88        Absolute unit of a cow stands over 6ft tall     t5_363r3   \n",
       "89                   The French Navy's bagpipe banger     t5_363r3   \n",
       "\n",
       "             subreddit             author upvotes comments   type  \\\n",
       "0   r/nextfuckinglevel   Agitated_Ad_1095    9888      225  video   \n",
       "1           r/BeAmazed  Remote_Return1716    3336       71  video   \n",
       "2           r/BeAmazed   reflective_map21    7594      185  video   \n",
       "3           r/BeAmazed           Majoodeh    2447      117  video   \n",
       "4   r/nextfuckinglevel      Mad_Bulls_007    1363       49  video   \n",
       "..                 ...                ...     ...      ...    ...   \n",
       "85          r/BeAmazed     Ultimate_Kurix    1371       12  video   \n",
       "86          r/BeAmazed    Natashaalovelyy     156       11  video   \n",
       "87  r/nextfuckinglevel        Parasyte-vn   30240      491  video   \n",
       "88          r/BeAmazed           Sunnyudd    2229       89  video   \n",
       "89          r/BeAmazed     freudian_nipps     705       59  video   \n",
       "\n",
       "                                               source  \n",
       "0   https://packaged-media.redd.it/fx2gtspphc6d1/p...  \n",
       "1   https://v.redd.it/15huvf874d6d1/HLSPlaylist.m3...  \n",
       "2   https://packaged-media.redd.it/0ngywg4swb6d1/p...  \n",
       "3   https://v.redd.it/cvvwhzbh8c6d1/HLSPlaylist.m3...  \n",
       "4   https://v.redd.it/9q8pct7trc6d1/HLSPlaylist.m3...  \n",
       "..                                                ...  \n",
       "85  https://packaged-media.redd.it/zhekp1j1x56d1/p...  \n",
       "86  https://packaged-media.redd.it/oag19gg7d96d1/p...  \n",
       "87  https://packaged-media.redd.it/oywy19clb26d1/p...  \n",
       "88  https://packaged-media.redd.it/9j4y0ykkx46d1/p...  \n",
       "89  https://v.redd.it/cxton7okm66d1/HLSPlaylist.m3...  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df = pd.DataFrame(content_dict_list)\n",
    "content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df.to_csv(f'{input_topic}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
